Metadata-Version: 2.1
Name: neuroinsight
Version: 1.0.0
Summary: Simulated BCI for Cognitive State Classification
Home-page: UNKNOWN
Author: BCI Projects Team
License: UNKNOWN
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Provides-Extra: dev
License-File: LICENSE

# NeuroInsight – Simulated BCI for Cognitive State Classification

🧠 A no-hardware Brain-Computer Interface (BCI) system that classifies cognitive states (focus, stress, relaxation) using synthetic EEG data.

## 🎯 Project Overview

NeuroInsight is a simulated BCI system designed to demonstrate cognitive state classification without requiring actual EEG hardware. It generates realistic synthetic EEG data for three distinct cognitive states and provides tools for analysis and machine learning.

### Cognitive States

- **Focus**: High beta waves (13-30 Hz) - Active thinking and concentration
- **Stress**: High beta + gamma waves (30-100 Hz) - Anxiety and high cognitive load
- **Relaxation**: High alpha waves (8-13 Hz) - Calm and relaxed state

## 🚀 Quick Start

### 1. Install Dependencies

```bash
# Install required Python libraries
pip install -r requirements.txt

# Or install the package in development mode
pip install -e .
```

### 2. Run the Demo

```bash
# Run the interactive demo
python demo_eeg_simulation.py

# Or use the command-line tool
neuroinsight-demo
```

### 3. Generate Custom Data

```python
from neuroinsight.eeg_simulator import EEGSimulator

# Initialize simulator
simulator = EEGSimulator(sampling_rate=256, duration=10.0)

# Generate EEG data for a specific state
eeg_data = simulator.generate_cognitive_state_eeg('focus', n_channels=8)

# Generate complete dataset
dataset = simulator.generate_dataset(samples_per_state=100, n_channels=8)
```

## 📦 Required Python Libraries

The following libraries are automatically installed via `requirements.txt`:

- **NumPy** (≥1.21.0) - Numerical computations and array operations
- **SciPy** (≥1.7.0) - Signal processing and scientific computing
- **Matplotlib** (≥3.5.0) - Plotting and visualization
- **Pandas** (≥1.3.0) - Data manipulation and analysis
- **Scikit-learn** (≥1.0.0) - Machine learning algorithms
- **MNE** (≥1.0.0) - EEG data handling and processing
- **PyEEG** (≥0.4.0) - EEG feature extraction
- **Seaborn** (≥0.11.0) - Statistical data visualization

## 🔬 EEG Signal Simulation

The simulator generates realistic EEG signals by combining:

1. **Frequency Band Components**: Alpha, beta, theta, delta, and gamma waves
2. **Band-Limited Noise**: Realistic noise within specific frequency ranges
3. **Channel Variations**: Different signal characteristics across EEG channels
4. **State-Specific Patterns**: Distinct frequency distributions for each cognitive state

### Frequency Bands

| Band | Frequency Range | Associated State |
|------|----------------|------------------|
| Delta | 0.5-4 Hz | Deep sleep |
| Theta | 4-8 Hz | Drowsiness, meditation |
| Alpha | 8-13 Hz | Relaxation, eyes closed |
| Beta | 13-30 Hz | Active thinking, focus |
| Gamma | 30-100 Hz | High-level processing, stress |

## 📊 Data Structure

The generated EEG data includes:

```python
{
    'data': np.ndarray,           # EEG signals (channels × time_points)
    'channel_names': List[str],   # Channel labels
    'sampling_rate': int,         # Hz
    'duration': float,            # seconds
    'time': np.ndarray,           # Time vector
    'state': str,                 # Cognitive state label
    'description': str,           # State description
    'metadata': dict              # Additional parameters
}
```

## 🎨 Visualization Features

The simulator provides comprehensive visualization tools:

- **Time Series Plots**: Raw EEG signals over time
- **Power Spectrum Analysis**: Frequency domain representation
- **Band Highlighting**: Visual identification of frequency bands
- **Multi-Channel Display**: Simultaneous view of all EEG channels

## 🔧 Customization

### Adjusting Signal Parameters

```python
# Customize cognitive state characteristics
simulator.cognitive_states['focus']['amplitudes']['beta'] = 1.0
simulator.cognitive_states['focus']['noise_level'] = 0.05

# Modify frequency bands
simulator.freq_bands['custom'] = (15, 25)
```

### Changing Recording Parameters

```python
# High-resolution recording
simulator = EEGSimulator(sampling_rate=512, duration=30.0)

# Multi-channel setup
eeg_data = simulator.generate_cognitive_state_eeg('stress', n_channels=16)
```

## 🧪 Validation and Testing

The simulator includes built-in validation features:

- **Signal Quality Checks**: Ensures realistic amplitude ranges
- **Frequency Band Verification**: Confirms proper frequency distributions
- **Noise Level Monitoring**: Maintains appropriate signal-to-noise ratios
- **Channel Consistency**: Validates cross-channel relationships

## 🔮 Future Enhancements

Planned features for upcoming versions:

- [ ] Real-time signal generation
- [ ] Advanced artifact simulation (eye blinks, muscle activity)
- [ ] Individual subject variability
- [ ] Integration with real EEG hardware
- [ ] Machine learning model training pipeline
- [ ] Web-based visualization interface

## 📚 Usage Examples

### Basic Usage

```python
from neuroinsight.eeg_simulator import EEGSimulator

# Create simulator
simulator = EEGSimulator()

# Generate single sample
eeg_data = simulator.generate_cognitive_state_eeg('focus')

# Plot results
simulator.plot_sample(eeg_data)
simulator.plot_power_spectrum(eeg_data)
```

### Dataset Generation

```python
# Generate training dataset
dataset = simulator.generate_dataset(samples_per_state=500, n_channels=8)

# Access data
X = np.array(dataset['data'])  # Shape: (n_samples, n_channels, n_timepoints)
y = dataset['labels']          # Shape: (n_samples,)
```

### Custom Analysis

```python
# Extract specific frequency bands
from scipy import signal

def extract_alpha_power(eeg_data):
    """Extract alpha band power from EEG data"""
    freqs, psd = signal.welch(eeg_data, fs=256)
    alpha_mask = (freqs >= 8) & (freqs <= 13)
    return np.mean(psd[alpha_mask])

# Apply to dataset
alpha_powers = [extract_alpha_power(sample) for sample in dataset['data']]
```

## 🤝 Contributing

Contributions are welcome! Please feel free to submit pull requests or open issues for:

- Bug fixes
- New features
- Documentation improvements
- Performance optimizations

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- Inspired by real BCI research and applications
- Built with open-source scientific computing tools
- Designed for educational and research purposes

---

**Note**: This is a simulation tool for educational and research purposes. For clinical applications, always use validated EEG hardware and follow appropriate medical protocols.


